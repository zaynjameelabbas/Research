# 📚 Research Portfolio – Zayn Abbas

Welcome to my research portfolio! This repository serves as a collection of my **published papers, works in progress, and ongoing research projects** in the fields of **human-computer interaction, emotion detection, social media communication, and AI-driven user research**.

## 🏛 About Me
I am a **Master’s student at the University of Guelph** with a focus on **how humans interpret and express emotion in text-based social media communication**. My research explores **user experience (UX), AI-driven emotion detection, and human-centered computing**. I am also a **software developer**, bringing a technical perspective to user research and digital interaction studies.

---

## 📄 Publications

### **1. Systematic Literature Review of Vision-Based Approaches to Outdoor Livestock Monitoring with Lessons from Wildlife Studies**  
📍 *Technical Report CSL-2024-01, School of Computer Science, University of Guelph*  
📌 [Link to Paper](https://github.com/zaynjameelabbas/Research/blob/main/publications/Systematic_Literature_Review_of_Vision-Based_Appro.pdf)  
📜 **Summary:** This systematic literature review explores the use of **computer vision and deep learning for precision livestock farming (PLF)**. It categorizes **vision-based methods for livestock and wildlife monitoring**, discusses the challenges of applying AI in outdoor settings, and highlights key advancements in **animal health and welfare monitoring**.  


### **2. Emotive Translation Bubbles: Visualizing Emotional Nuances in Text Communication**  
📍 *Graphics Interface (GI) 2023*  
📌 [Link to Paper (if available)]()  
📜 **Summary:** This paper presents a novel visualization technique—Emotive Translation Bubbles—designed to **help users better understand emotional nuances in text-based digital communication**. The study explores how different **emotion translation models** can enhance interpersonal understanding in online conversations.  

---

## 🚀 Works in Progress

### **1. Rethinking “Ground Truth” in AI Emotion Detection: Insights from a Human-Centred Study of Emotion Labelling**  
📍 *Graphics Interface (GI) 2025*  
📌 [Link to Paper (if available)]()  
📜 **Summary:** This study explores the limitations of AI emotion detection models trained on predefined emotion labels. Using a mixed-methods user study, we analyze how human interpretations of emotion in text-based communication diverge from standard AI-labeled datasets. The findings highlight the need for **pluralistic AI models** that accommodate individual differences in emotional expression.  


---

## 🔬 Research Interests  
- **Human-Computer Interaction (HCI)** – User experience, usability studies, and emotion-driven interaction  
- **AI & Emotion Detection** – Improving AI models to **better understand human emotions** in digital communication  
- **User Research in Gaming & Social Media** – Studying **player behavior, motivation, and UX improvements** for interactive digital experiences  
- **Natural Language Processing (NLP)** – Sentiment analysis, conversational AI, and multimodal emotion recognition  

---

## 📬 Contact  
Feel free to connect with me for research collaborations, discussions, or inquiries!  
📧 Email: [zayn.jameel.abbas@gmail.com]  
🌐 LinkedIn: [https://www.linkedin.com/in/zayn-j-abbas/]  
---

## 📌 Repository Structure

📂 publications/
├── 📜 Systematic_Literature_Review_of_Vision.pdf
├── 📜 Other_Published_Work.pdf
📂 works-in-progress/
├── 📜 Multimodal_Emotion_Research.pdf
├── 📜 AI_Chatbot_Personalization_Research.pdf
